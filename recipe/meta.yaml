{% set name = "apache-airflow-providers-databricks" %}
{% set version = "4.3.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/apache-airflow-providers-databricks-{{ version }}.tar.gz
  sha256: e33dcd6bbbdd998448b2dad1e9383cc1c7a6cd79abfb000088da5e5af9642e4d

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.8
    - setuptools >=67.2.0,<68.0.0
    - pip
  run:
    - python >=3.8
    - aiohttp >=3.6.3,<4
    - apache-airflow-providers-common-sql >=1.5.0
    - apache-airflow >=2.4.0
    - databricks-sql-connector >=2.0.0,<3.0.0
    - requests >=2.27,<3

test:
  imports:
    - airflow.providers.databricks
    - airflow.providers.databricks.hooks
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://airflow.apache.org/
  summary: Provider for Apache Airflow. Implements apache-airflow-providers-databricks package
  license: Apache-2.0
  license_file:
    - LICENSE
    - NOTICE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
