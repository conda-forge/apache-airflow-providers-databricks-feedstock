{% set name = "apache-airflow-providers-databricks" %}
{% set version = "4.1.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/apache-airflow-providers-databricks-{{ version }}.tar.gz
  sha256: 4ba145e6cb8cf63e4b5f99c843f1b09bbdacc553e9a76942369f3ab4c7135ae5

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.7
    - setuptools >=67.2.0
    - pip
  run:
    - python >=3.7
    - aiohttp >=3.6.3,<4
    - apache-airflow-providers-common-sql >=1.3.1
    - apache-airflow >=2.3.0
    - databricks-sql-connector >=2.0.0,<3.0.0
    - requests >=2.27,<3

test:
  imports:
    - airflow.providers.databricks
    - airflow.providers.databricks.hooks
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://airflow.apache.org/
  summary: Provider for Apache Airflow. Implements apache-airflow-providers-databricks package
  license: Apache-2.0
  license_file:
    - LICENSE
    - NOTICE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
