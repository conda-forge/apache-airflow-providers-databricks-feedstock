{% set name = "apache-airflow-providers-databricks" %}
{% set version = "7.7.1" %}
{% set python_min = "3.10" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/apache_airflow_providers_databricks-{{ version }}.tar.gz
  sha256: d7625197070e2103a68401e4c2322caf8dc381b5ae148b770d3063d005a1f213

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - flit-core ==3.12.0
    - pip
  run:
    - python >={{ python_min }}
    - apache-airflow >=2.10.0
    - apache-airflow-providers-common-compat >=1.6.0
    - apache-airflow-providers-common-sql >=1.27.0
    - apache-airflow-providers-openlineage >=2.3.0
    - requests >=2.32.0,<3
    - databricks-sql-connector >=4.0.0
    - databricks-sqlalchemy >=1.0.2
    - aiohttp >=3.9.2,<4
    - mergedeep >=1.3.4
    - pandas >=2.1.2
    - pyarrow >=16.1.0

test:
  imports:
    - airflow.providers.databricks
  commands:
    - pip check
  requires:
    - python {{ python_min }}
    - pip

about:
  home: https://airflow.apache.org/
  summary: Provider package apache-airflow-providers-databricks for Apache Airflow
  license: Apache-2.0
  license_file: src/airflow/providers/databricks/LICENSE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
