{% set name = "apache-airflow-providers-databricks" %}
{% set version = "6.10.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/apache_airflow_providers_databricks-{{ version }}.tar.gz
  sha256: 63b63e1a031489f55410b905d697577f5829898d21895ec4dba427fa989fd29c

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python >=3.8,<4.dev0
    - flit-core >=3.2,<4
    - pip
  run:
    - python >=3.8,<4.dev0
    - aiohttp >=3.9.2,<4
    - apache-airflow-providers-common-sql >=1.10.0
    - apache-airflow >=2.8.0
    - databricks-sql-connector >=2.0.0,<3.0.0,!=2.9.0
    - mergedeep >=1.3.4
    - pandas >=2.1.2,<2.2
    - pyarrow >=14.0.1
    - requests >=2.27.0,<3

test:
  imports:
    - airflow.providers.databricks
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://airflow.apache.org/
  summary: Provider package apache-airflow-providers-databricks for Apache Airflow
  license: Apache-2.0
  license_file: airflow/providers/databricks/LICENSE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
