{% set name = "apache-airflow-providers-databricks" %}
{% set version = "7.3.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/apache_airflow_providers_databricks-{{ version }}.tar.gz
  sha256: 07b8e64b2d6b29de6f181792e5e3c5f00798111a8f154fce3d731a04a407784c

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - flit-core ==3.12.0
    - pip
  run:
    - python >={{ python_min }}
    - apache-airflow >=2.9.0
    - apache-airflow-providers-common-sql >=1.20.0
    - requests >=2.31.0,<3
    - databricks-sql-connector >=3.0.0
    - aiohttp >=3.9.2,<4
    - mergedeep >=1.3.4
    - pandas >=2.1.2,<2.2
    - pyarrow >=14.0.1

test:
  imports:
    - airflow.providers.databricks
  commands:
    - pip check
  requires:
    - python {{ python_min }}
    - pip

about:
  home: https://airflow.apache.org/
  summary: Provider package apache-airflow-providers-databricks for Apache Airflow
  license: Apache-2.0
  license_file: src/airflow/providers/databricks/LICENSE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
